{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Classification6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cYd4rjsEVrX"
      },
      "source": [
        "!gdown --id 1KAHAAWeSANdc0R17lsAYePB11qEbQoeO\n",
        "!unzip -oqq AI_Hack-20210423T085210Z-001.zip\n",
        "!gdown --id 1nIIwTQ9F0hiV4_F1zGmLrm8pMExLf53s\n",
        "!unzip -oqq AI_Hack-20210423T085210Z-002.zip\n",
        "!gdown --id 1kV6Od7IhbHo0yy4BZGYHFRjqnvtSY6GQ\n",
        "!unzip -oqq AI_Hack-20210423T085210Z-003.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSQDshsiH1Ob"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from torchvision import transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW8_RTor2unH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-_to27xH1Of"
      },
      "source": [
        "## Датасет\n",
        "\n",
        "Прежде чем разбираться с моделями, нам надо в первую очередь разобраться с тем, как грузить датасет. Давайте напишем класс в торче для этого. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDuqNpUhH1Og"
      },
      "source": [
        "# задаем преобразование изображения\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "\n",
        "\n",
        "    transforms.RandomRotation((90, 90)),\n",
        "\n",
        "    # transforms.RandomCrop(1024),\n",
        "    transforms.CenterCrop(1024* np.random.uniform(0.5, 2)),\n",
        "    transforms.Resize(1024),\n",
        "    transforms.CenterCrop(1024),\n",
        "\n",
        "    # transforms.RandomPerspective(),\n",
        "    transforms.RandomVerticalFlip(), \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomGrayscale(),    \n",
        "    # transforms.AutoAugment(),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(1024),\n",
        "    transforms.CenterCrop(1024),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "    #transforms.ToPILImage()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Leic0tWEVy2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vWqvjjALPTS"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGM_DHOZH1Og"
      },
      "source": [
        "# читаем датасет\n",
        "\n",
        "#data_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "imagenet_data = torchvision.datasets.ImageFolder('AI_Hack', transform=train_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yetRNvxLogd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6JC-2M7Myct"
      },
      "source": [
        "imagenet_data.class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMdkQuczH1Oh"
      },
      "source": [
        "Довольно похожие, согласны?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTWQ3iOAH1Oh"
      },
      "source": [
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "\n",
        "dataset_size = len(imagenet_data)\n",
        "print(dataset_size)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split*dataset_size))\n",
        "if shuffle_dataset:\n",
        "  np.random.seed(random_seed)\n",
        "  np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(imagenet_data,\n",
        "                                           batch_size=2,\n",
        "                                           sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(imagenet_data,\n",
        "                                           batch_size=2,\n",
        "                                           sampler=valid_sampler)\n",
        "print(len(train_loader), len(valid_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzT9JPpH1Oi"
      },
      "source": [
        "Отлично, теперь давайте напишем пару вспомогательных функций для визуализации и тренировки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SufIxZhmH1Oj"
      },
      "source": [
        "## Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMa6oIsdH1Oj"
      },
      "source": [
        "def plot_history(train_history, val_history, title='loss'):\n",
        "    plt.figure()\n",
        "    plt.title('{}'.format(title))\n",
        "    plt.plot(train_history, label='train', zorder=1)\n",
        "    \n",
        "    points = np.array(val_history)\n",
        "    steps = list(range(0, len(train_history) + 1, int(len(train_history) / len(val_history))))[1:]\n",
        "    \n",
        "    plt.scatter(steps, val_history, marker='+', s=180, c='orange', label='val', zorder=2)\n",
        "    plt.xlabel('train steps')\n",
        "    \n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NvRkqh4H1Oj"
      },
      "source": [
        "def train(model, criterion, optimizer, train_dataloader, test_dataloader, NUM_EPOCH=15):\n",
        "    train_loss_log = []\n",
        "    val_loss_log = []\n",
        "    \n",
        "    train_acc_log = []\n",
        "    val_acc_log = []\n",
        "    \n",
        "    for epoch in tqdm(range(NUM_EPOCH)):\n",
        "        model.train()\n",
        "        train_loss = 0.\n",
        "        train_size = 0\n",
        "        \n",
        "        train_pred = 0.\n",
        "\n",
        "        for imgs, labels in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            y_pred = model(imgs)\n",
        "\n",
        "            loss = criterion(y_pred, labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            train_size += y_pred.size(0)\n",
        "            train_loss_log.append(loss.data / y_pred.size(0))\n",
        "            \n",
        "            train_pred += (y_pred.argmax(1) == labels).sum()\n",
        "\n",
        "            optimizer.step()\n",
        "        \n",
        "        train_acc_log.append(train_pred / train_size)\n",
        "\n",
        "        val_loss = 0.\n",
        "        val_size = 0\n",
        "        \n",
        "        val_pred = 0.\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in test_dataloader:\n",
        "                \n",
        "                imgs = imgs.cuda()\n",
        "                labels = labels.cuda()\n",
        "                \n",
        "                pred = model(imgs)\n",
        "                loss = criterion(pred, labels)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "                val_size += pred.size(0)\n",
        "                \n",
        "                val_pred += (pred.argmax(1) == labels).sum()\n",
        "\n",
        "        val_loss_log.append(val_loss / val_size)\n",
        "        val_acc_log.append(val_pred / val_size)\n",
        "\n",
        "        clear_output()\n",
        "        plot_history(train_loss_log, val_loss_log, 'loss')\n",
        "\n",
        "        print('Train loss:', (train_loss / train_size)*100)\n",
        "        print('Val loss:', (val_loss / val_size)*100)\n",
        "        print('Train acc:', (train_pred / train_size)*100)\n",
        "        print('Val acc:', (val_pred / val_size)*100)\n",
        "        \n",
        "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiazR7GaH1Oj"
      },
      "source": [
        "## Модель\n",
        "Все, перейдем к обучению самой модели. Воспользуемся предобученным резнетом и заменим у него классификатор, а потом будем обучать только его."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3dM6ZHrH1Oj"
      },
      "source": [
        "model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_swsl')\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 13)\n",
        "\n",
        "model = model.cuda()\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BewDYtsoH1Ok"
      },
      "source": [
        "# optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.0001)\n",
        "plist = [{'params': model.parameters(), 'lr': 1e-5}]\n",
        "optimizer = optim.Adam(plist, lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SknWdofkp9hf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p55y9nALo_pj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZveKP5W4H1Ok"
      },
      "source": [
        "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, \n",
        "                                                                 criterion, \n",
        "                                                                 optimizer, \n",
        "                                                                 train_loader, \n",
        "                                                                 valid_loader, \n",
        "                                                                 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kDUMFaaU3eG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wighSctAVuJf"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "class F1Score:\n",
        "    \"\"\"\n",
        "    Class for f1 calculation in Pytorch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, average: str = 'weighted'):\n",
        "        \"\"\"\n",
        "        Init.\n",
        "\n",
        "        Args:\n",
        "            average: averaging method\n",
        "        \"\"\"\n",
        "        self.average = average\n",
        "        if average not in [None, 'micro', 'macro', 'weighted']:\n",
        "            raise ValueError('Wrong value of average parameter')\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_f1_micro(predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate f1 micro.\n",
        "\n",
        "        Args:\n",
        "            predictions: tensor with predictions\n",
        "            labels: tensor with original labels\n",
        "\n",
        "        Returns:\n",
        "            f1 score\n",
        "        \"\"\"\n",
        "        true_positive = torch.eq(labels, predictions).sum().float()\n",
        "        f1_score = torch.div(true_positive, len(labels))\n",
        "        return f1_score\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_f1_count_for_label(predictions: torch.Tensor,\n",
        "                                labels: torch.Tensor, label_id: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Calculate f1 and true count for the label\n",
        "\n",
        "        Args:\n",
        "            predictions: tensor with predictions\n",
        "            labels: tensor with original labels\n",
        "            label_id: id of current label\n",
        "\n",
        "        Returns:\n",
        "            f1 score and true count for label\n",
        "        \"\"\"\n",
        "        # label count\n",
        "        true_count = torch.eq(labels, label_id).sum()\n",
        "\n",
        "        # true positives: labels equal to prediction and to label_id\n",
        "        true_positive = torch.logical_and(torch.eq(labels, predictions),\n",
        "                                          torch.eq(labels, label_id)).sum().float()\n",
        "        # precision for label\n",
        "        precision = torch.div(true_positive, torch.eq(predictions, label_id).sum().float())\n",
        "        # replace nan values with 0\n",
        "        precision = torch.where(torch.isnan(precision),\n",
        "                                torch.zeros_like(precision).type_as(true_positive),\n",
        "                                precision)\n",
        "\n",
        "        # recall for label\n",
        "        recall = torch.div(true_positive, true_count)\n",
        "        # f1\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "        # replace nan values with 0\n",
        "        f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1).type_as(true_positive), f1)\n",
        "        return f1, true_count\n",
        "\n",
        "    def __call__(self, predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate f1 score based on averaging method defined in init.\n",
        "\n",
        "        Args:\n",
        "            predictions: tensor with predictions\n",
        "            labels: tensor with original labels\n",
        "\n",
        "        Returns:\n",
        "            f1 score\n",
        "        \"\"\"\n",
        "\n",
        "        # simpler calculation for micro\n",
        "        if self.average == 'micro':\n",
        "            return self.calc_f1_micro(predictions, labels)\n",
        "\n",
        "        f1_score = 0\n",
        "        for label_id in range(1, len(labels.unique()) + 1):\n",
        "            f1, true_count = self.calc_f1_count_for_label(predictions, labels, label_id)\n",
        "\n",
        "            if self.average == 'weighted':\n",
        "                f1_score += f1 * true_count\n",
        "            elif self.average == 'macro':\n",
        "                f1_score += f1\n",
        "\n",
        "        if self.average == 'weighted':\n",
        "            f1_score = torch.div(f1_score, len(labels))\n",
        "        elif self.average == 'macro':\n",
        "            f1_score = torch.div(f1_score, len(labels.unique()))\n",
        "\n",
        "        return f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsoiDdu3XTg-"
      },
      "source": [
        "true_labels = torch.Tensor().cuda()\n",
        "predictions = torch.Tensor().cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(valid_loader):\n",
        "        \n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "        pred = model(imgs).argmax(dim=1)\n",
        "        \n",
        "        true_labels = torch.cat(\n",
        "                                    (true_labels, labels)\n",
        "                                    ,dim=0\n",
        "                                )\n",
        "        predictions = torch.cat(\n",
        "                                    (predictions, pred)\n",
        "                                    ,dim=0\n",
        "                                )\n",
        "\n",
        "f1_metric = F1Score('macro')\n",
        "f1_metric(predictions, true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtUqUNbdpgXB"
      },
      "source": [
        "import pickle\n",
        "import torch\n",
        "#torch.save(model, 'model.pt')#Сохраняем"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ET3US_4xOm8"
      },
      "source": [
        "model=torch.load('drive/MyDrive/model.pt')#Загружаем"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svL_O8IrH1Ok"
      },
      "source": [
        "## Посмотрим метрики нашей итоговой модели на валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfhqWAitxcWs"
      },
      "source": [
        "classDict = {0: 'Муравьед',#Словарь из (номер класса:имя)\n",
        "             1: 'Коала',\n",
        "             2: 'Плащевидная ящерица',\n",
        "             3: 'Крокодил',\n",
        "             4: 'Дельфин',\n",
        "             5: 'Лягушки',\n",
        "             6: 'Осьминог',\n",
        "             7: 'Попугай',\n",
        "             8: 'Черепаха',\n",
        "             9: 'Вомбат',\n",
        "             10: 'Кенгуру',\n",
        "             11: 'Обезьяна',\n",
        "             12: 'Пустой фон'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huUsN0WxDuR-"
      },
      "source": [
        "def Predict(path):\n",
        "  image=cv2.imread(path)\n",
        "  model=torch.load('drive/MyDrive/model.pt')\n",
        "  image=valid_transform(image)\n",
        "  if torch.cuda.is_available():\n",
        "    model=model.cuda()\n",
        "    image = image.cuda()\n",
        "    print('Есть Cuda')\n",
        "  else:\n",
        "    model=model.cpu()\n",
        "    image = image.cpu()\n",
        "    print('Нет Cuda')\n",
        "\n",
        "  model.eval()\n",
        "  pred = model(image[None, ...]) \n",
        "  return classDict[pred.argmax().item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg47zEMba3kt"
      },
      "source": [
        "Predict('1.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3VnYz2L3SBt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}